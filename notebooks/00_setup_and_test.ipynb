{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Test GitHub Data Collection\n",
    "\n",
    "This notebook will help you:\n",
    "1. Set up your GitHub token\n",
    "2. Test the data collector\n",
    "3. Collect data for your first Stadium project\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important: Use Virtual Environment\n",
    "\n",
    "**Before running this notebook:**\n",
    "\n",
    "```bash\n",
    "# 1. Create and activate virtual environment (if not already done)\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "# 2. Install packages\n",
    "pip install -r requirements.txt\n",
    "pip install -e .\n",
    "\n",
    "# 3. Install Jupyter kernel for this venv\n",
    "python -m ipykernel install --user --name=categories-venv --display-name=\"Python (Categories)\"\n",
    "\n",
    "# 4. Start Jupyter from the venv\n",
    "jupyter lab\n",
    "```\n",
    "\n",
    "Then select the **\"Python (Categories)\"** kernel for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify Setup\n",
    "\n",
    "Check that all required packages are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.6 (default, Nov 11 2024, 03:15:38) \n",
      "[Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "Executable: /Users/ibrahimcesar/Dev/categories-of-the-commons/venv/bin/python\n",
      "\n",
      "‚úÖ All required packages installed!\n",
      "   - PyGithub: 2.8.1\n",
      "   - tqdm: 4.67.1\n",
      "   - python-dotenv: 1.2.1\n"
     ]
    }
   ],
   "source": [
    "# Verify packages\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Executable: {sys.executable}\")\n",
    "\n",
    "try:\n",
    "    import github\n",
    "    import tqdm\n",
    "    import dotenv\n",
    "    from importlib.metadata import version\n",
    "    print(\"\\n‚úÖ All required packages installed!\")\n",
    "    print(f\"   - PyGithub: {version('PyGithub')}\")\n",
    "    print(f\"   - tqdm: {version('tqdm')}\")\n",
    "    print(f\"   - python-dotenv: {version('python-dotenv')}\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ùå Missing package: {e}\")\n",
    "    print(\"\\nPlease run from terminal:\")\n",
    "    print(\"  pip install PyGithub tqdm python-dotenv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load GitHub Token\n",
    "\n",
    "**Get your token:**\n",
    "1. Go to: https://github.com/settings/tokens\n",
    "2. Click **\"Generate new token (classic)\"**\n",
    "3. Name: `categories-of-the-commons`\n",
    "4. Select scopes:\n",
    "   - ‚úì `public_repo`\n",
    "   - ‚úì `read:org`\n",
    "   - ‚úì `read:user`\n",
    "5. Click **\"Generate token\"**\n",
    "6. Copy the token (starts with `ghp_`)\n",
    "7. Add to `.env` file: `GITHUB_TOKEN=ghp_your_token_here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\n# Load from .env file (in project root)\nenv_path = Path(\"../.env\")\nif env_path.exists():\n    load_dotenv(env_path)\n    print(f\"‚úÖ Loaded .env from {env_path.resolve()}\")\nelse:\n    load_dotenv()  # Try default locations\n    print(\"‚ö†Ô∏è  No .env file found in project root\")\n    print(\"   Please copy .env.example to .env and add your token:\")\n    print(\"   cp ../.env.example ../.env\")\n\nGITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n\nif not GITHUB_TOKEN:\n    print(\"\\n‚ùå GITHUB_TOKEN not found!\")\n    print(\"   1. Copy .env.example to .env: cp ../.env.example ../.env\")\n    print(\"   2. Edit .env and add your GitHub token\")\n    print(\"   3. Get a token at: https://github.com/settings/tokens\")\nelif GITHUB_TOKEN == \"your_github_token_here\":\n    print(\"\\n‚ö†Ô∏è  GITHUB_TOKEN is still the placeholder!\")\n    print(\"   Edit ../.env and replace with your actual token\")\nelse:\n    print(f\"‚úÖ Token loaded (length: {len(GITHUB_TOKEN)})\")\n    print(f\"   Token preview: {GITHUB_TOKEN[:7]}...{GITHUB_TOKEN[-4:]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Collector & Check Rate Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub API Rate Limits:\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Core API:    4998 /  5000 remaining\n",
      "Search API:  4998 /  5000 remaining\n",
      "Resets at:  2025-11-25 14:54:59+00:00\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "‚úÖ Plenty of API calls available!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from collection.github_collector import GitHubCollector\n",
    "\n",
    "# Initialize collector\n",
    "collector = GitHubCollector(token=GITHUB_TOKEN)\n",
    "\n",
    "# Check rate limits\n",
    "rate_limit = collector.get_rate_limit()\n",
    "\n",
    "print(\"GitHub API Rate Limits:\")\n",
    "print(\"‚îÅ\" * 50)\n",
    "print(f\"Core API:   {rate_limit['core']['remaining']:5d} / {rate_limit['core']['limit']:5d} remaining\")\n",
    "print(f\"Search API: {rate_limit['search']['remaining']:5d} / {rate_limit['search']['limit']:5d} remaining\")\n",
    "print(f\"Resets at:  {rate_limit['core']['reset']}\")\n",
    "print(\"‚îÅ\" * 50)\n",
    "\n",
    "if rate_limit['core']['remaining'] > 4000:\n",
    "    print(\"‚úÖ Plenty of API calls available!\")\n",
    "elif rate_limit['core']['remaining'] > 1000:\n",
    "    print(\"‚ö†Ô∏è  Moderate API calls remaining\")\n",
    "else:\n",
    "    print(\"üî¥ Low API calls - may need to wait\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Quick Test - Check Maintainer Count\n",
    "\n",
    "Let's verify a Stadium candidate by checking maintainer count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test on curl - confirmed Stadium project\ntest_repo = \"curl/curl\"\n\nprint(f\"Testing: {test_repo}\")\nprint(\"‚îÅ\" * 50)\n\n# Get maintainer data\nmaintainers = collector.collect_maintainer_data(test_repo)\n\nprint(f\"\\nüìä Maintainer Analysis:\")\nprint(f\"   Total collaborators:     {maintainers['statistics']['total_collaborators']}\")\nprint(f\"   From files (parsed):     {maintainers['statistics']['maintainers_from_files_count']}\")\nprint(f\"   Active (6 months):       {maintainers['statistics']['active_maintainers_6mo']}\")\n\nif maintainers['maintainers_from_files']:\n    print(f\"\\nüë• Maintainers from files:\")\n    print(f\"   {', '.join(maintainers['maintainers_from_files'])}\")\n\nprint(f\"\\nüë• Top Committers (last 6 months):\")\nfor committer in maintainers['top_committers'][:5]:\n    print(f\"   - {committer['login']:20s} {committer['commits_6mo']:4d} commits\")\n\n# Get contributor data for entropy classification\nprint(\"\\n\" + \"‚îÅ\" * 50)\nprint(\"üìà Entropy-Based Classification:\")\ncontributors = collector.collect_contributor_data(test_repo, max_contributors=100)\n\nfrom analysis.entropy_calculation import EntropyCalculator\nentropy_calc = EntropyCalculator()\nclassification = entropy_calc.classify_project(contributors)\n\nprint(f\"\\n   Classification: {classification['classification']}\")\nprint(f\"   Confidence: {classification['confidence']:.0%}\")\nprint(f\"   Stadium Score: {classification.get('stadium_score', 'N/A')}/3 criteria met\")\nprint(f\"\\n   Metrics:\")\nfor key, value in classification['metrics'].items():\n    if isinstance(value, float):\n        print(f\"      {key}: {value:.3f}\")\n    else:\n        print(f\"      {key}: {value}\")\n\nprint(f\"\\n   Criteria Met: {', '.join(classification['criteria_met']) or 'None'}\")\nprint(\"‚îÅ\" * 50)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Collect Complete Dataset\n",
    "\n",
    "Now let's collect a full dataset for curl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect complete dataset\n",
    "repo = \"curl/curl\"\n",
    "\n",
    "print(f\"\\nüöÄ Collecting complete dataset for: {repo}\")\n",
    "print(\"This will take a few minutes...\\n\")\n",
    "\n",
    "data = collector.collect_complete_dataset(repo, since_days=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Examine Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLLECTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Repository: {repo}\")\n",
    "print(f\"Stars: {data['repository'].get('stargazers_count', 'N/A'):,}\")\n",
    "print(f\"Forks: {data['repository'].get('forks_count', 'N/A'):,}\")\n",
    "print(f\"Language: {data['repository'].get('language', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nüë• Maintainers:\")\n",
    "print(f\"   Collaborators:  {data['maintainers']['statistics'].get('total_collaborators', 0)}\")\n",
    "print(f\"   From files:     {data['maintainers']['statistics'].get('maintainers_from_files_count', 0)}\")\n",
    "print(f\"   Active (6mo):   {data['maintainers']['statistics'].get('active_maintainers_6mo', 0)}\")\n",
    "\n",
    "print(f\"\\nüìà Activity:\")\n",
    "print(f\"   Contributors: {len(data['contributors'])}\")\n",
    "print(f\"   Commits:      {len(data['recent_commits'])}\")\n",
    "\n",
    "print(f\"\\nüîÄ Pull Requests:\")\n",
    "pr_stats = data['pull_requests']['statistics']\n",
    "print(f\"   Total:          {pr_stats.get('total_prs', 0)}\")\n",
    "print(f\"   Merged:         {pr_stats.get('merged_count', 0)}\")\n",
    "if pr_stats.get('total_prs', 0) > 0:\n",
    "    print(f\"   Merge rate:     {pr_stats.get('merged_count', 0) / pr_stats['total_prs'] * 100:.1f}%\")\n",
    "    print(f\"   Avg time:       {pr_stats.get('avg_time_to_merge', 0):.1f} hours\")\n",
    "    print(f\"   Conflict rate:  {pr_stats.get('conflict_rate', 0) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nüêõ Issues:\")\n",
    "issue_stats = data['issues']['statistics']\n",
    "print(f\"   Total:         {issue_stats.get('total_issues', 0)}\")\n",
    "print(f\"   Closed:        {issue_stats.get('closed_count', 0)}\")\n",
    "if issue_stats.get('total_issues', 0) > 0:\n",
    "    print(f\"   Avg time:      {issue_stats.get('avg_time_to_close', 0):.1f} hours\")\n",
    "    print(f\"   Bugs:          {issue_stats.get('bug_count', 0)}\")\n",
    "    print(f\"   Enhancements:  {issue_stats.get('enhancement_count', 0)}\")\n",
    "\n",
    "print(f\"\\nüìã Governance Files:\")\n",
    "gov_files = [k for k, v in data['governance_files'].items() if v]\n",
    "if gov_files:\n",
    "    for f in gov_files:\n",
    "        print(f\"   ‚úì {f}\")\n",
    "else:\n",
    "    print(\"   - None found\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Save to data/raw/\n",
    "output_path = Path(\"../data/raw\") / f\"{repo.replace('/', '_')}_data.json\"\n",
    "collector.save_data(data, output_path)\n",
    "\n",
    "print(f\"\\nüíæ Data saved to: {output_path}\")\n",
    "print(f\"   File size: {output_path.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Quick Validation - Is this a Stadium Project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_stadium_project(data):\n",
    "    \"\"\"Check if project meets Stadium criteria.\"\"\"\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # 1. Maintainer count\n",
    "    active_maintainers = data['maintainers']['statistics']['active_maintainers_6mo']\n",
    "    if active_maintainers <= 3:\n",
    "        checks.append((True, f\"‚úÖ Maintainers: {active_maintainers} ‚â§ 3\"))\n",
    "    else:\n",
    "        checks.append((False, f\"‚ùå Maintainers: {active_maintainers} > 3\"))\n",
    "    \n",
    "    # 2. Activity\n",
    "    commits = len(data['recent_commits'])\n",
    "    if commits >= 50:  # At least 50 commits in last year\n",
    "        checks.append((True, f\"‚úÖ Activity: {commits} commits/year\"))\n",
    "    else:\n",
    "        checks.append((False, f\"‚ö†Ô∏è  Activity: {commits} commits/year (low)\"))\n",
    "    \n",
    "    # 3. Impact (stars as proxy)\n",
    "    stars = data['repository']['stargazers_count']\n",
    "    if stars >= 1000:\n",
    "        checks.append((True, f\"‚úÖ Impact: {stars:,} stars\"))\n",
    "    else:\n",
    "        checks.append((False, f\"‚ö†Ô∏è  Impact: {stars:,} stars (low)\"))\n",
    "    \n",
    "    # 4. Contributors (should have some, but not too many)\n",
    "    contributors = len(data['contributors'])\n",
    "    if 10 <= contributors <= 200:\n",
    "        checks.append((True, f\"‚úÖ Contributors: {contributors} (balanced)\"))\n",
    "    elif contributors > 200:\n",
    "        checks.append((False, f\"‚ö†Ô∏è  Contributors: {contributors} (high, may be Federation)\"))\n",
    "    else:\n",
    "        checks.append((False, f\"‚ö†Ô∏è  Contributors: {contributors} (low)\"))\n",
    "    \n",
    "    print(\"\\nüéØ Stadium Validation:\")\n",
    "    print(\"‚îÅ\" * 50)\n",
    "    for passed, message in checks:\n",
    "        print(f\"   {message}\")\n",
    "    print(\"‚îÅ\" * 50)\n",
    "    \n",
    "    all_passed = all(check[0] for check in checks[:2])  # Must pass first 2\n",
    "    if all_passed:\n",
    "        print(\"\\n‚úÖ STADIUM PROJECT CONFIRMED!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Does not meet Stadium criteria\")\n",
    "        print(\"\\nüí° Tip: Check dominance patterns in top_committers.\")\n",
    "        print(\"   Even with >3 active maintainers, strong dominance by 1-2\")\n",
    "        print(\"   contributors may indicate Stadium-like characteristics.\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "# Run validation\n",
    "is_stadium = validate_stadium_project(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Check Dominance Patterns\n",
    "\n",
    "For projects with >3 active maintainers, check if 1-2 are dominant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate contributor dominance\n",
    "if len(data['contributors']) > 0:\n",
    "    total_contributions = sum(c['contributions'] for c in data['contributors'])\n",
    "    top_contributor = data['contributors'][0]\n",
    "    dominance_ratio = top_contributor['contributions'] / total_contributions\n",
    "    \n",
    "    print(f\"\\nüìä Contributor Dominance Analysis:\")\n",
    "    print(f\"   Top contributor: {top_contributor['login']}\")\n",
    "    print(f\"   Contributions:   {top_contributor['contributions']:,} / {total_contributions:,}\")\n",
    "    print(f\"   Dominance ratio: {dominance_ratio * 100:.1f}%\")\n",
    "    \n",
    "    if dominance_ratio > 0.4:  # >40% of contributions\n",
    "        print(f\"\\n‚úÖ STRONG DOMINANCE - Stadium-like characteristics!\")\n",
    "        print(f\"   Even with {data['maintainers']['statistics']['active_maintainers_6mo']} active maintainers,\")\n",
    "        print(f\"   {top_contributor['login']} controls {dominance_ratio * 100:.1f}% of contributions.\")\n",
    "    elif dominance_ratio > 0.25:  # >25% of contributions\n",
    "        print(f\"\\n‚ö†Ô∏è  MODERATE DOMINANCE\")\n",
    "    else:\n",
    "        print(f\"\\nüìä DISTRIBUTED CONTRIBUTIONS\")\n",
    "        print(f\"   May be Federation-type project.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've successfully collected data for one project, you can:\n",
    "\n",
    "1. **Verify more Stadium candidates:**\n",
    "   - See `data/stadium_candidates.md` for the list\n",
    "   - Run `collect_maintainer_data()` to quickly check maintainer counts\n",
    "\n",
    "2. **Calculate entropy:**\n",
    "   - Use `src/analysis/entropy_calculation.py`\n",
    "   - See notebook `01_data_exploration.ipynb`\n",
    "\n",
    "3. **Batch collection:**\n",
    "   - Collect data for multiple projects\n",
    "   - Create a script to iterate through candidates\n",
    "\n",
    "---\n",
    "\n",
    "**Rate limit check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining rate limit\n",
    "rate_limit = collector.get_rate_limit()\n",
    "print(f\"\\nüìä Rate Limit After Collection:\")\n",
    "print(f\"   Core API: {rate_limit['core']['remaining']}/{rate_limit['core']['limit']} remaining\")\n",
    "print(f\"   Used: {5000 - rate_limit['core']['remaining']} calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Step 10: Using Candidate Lists\n\nWe have pre-defined candidate lists for each governance category:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import candidate lists\nsys.path.insert(0, '../data')\nfrom candidates import (\n    STADIUM_COLLECTED, STADIUM_HIGH_PRIORITY, STADIUM_ALL,\n    FEDERATION_CANDIDATES, FEDERATION_HIGH_PRIORITY,\n    CLUB_CANDIDATES, CLUB_HIGH_PRIORITY,\n    TOY_CANDIDATES, TOY_HIGH_PRIORITY,\n    get_uncollected, print_status\n)\n\n# Show collection status across all categories\nprint_status()\n\n# Example: Get uncollected Stadium projects\nuncollected_stadium = get_uncollected(\"stadium\")\nprint(f\"\\nUncollected Stadium projects: {len(uncollected_stadium)}\")\nif uncollected_stadium[:5]:\n    print(\"Next to collect:\")\n    for repo in uncollected_stadium[:5]:\n        print(f\"  - {repo}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Categories)",
   "language": "python",
   "name": "categories-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}