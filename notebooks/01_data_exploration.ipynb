{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Exploration & Entropy Analysis\n",
    "\n",
    "This notebook explores collected GitHub data and calculates entropy metrics for Stadium project classification.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run `00_setup_and_test.ipynb` first to collect data\n",
    "- Data files should exist in `data/raw/`\n",
    "\n",
    "**Goals:**\n",
    "1. Load and explore collected project data\n",
    "2. Calculate contributor entropy (Shannon entropy)\n",
    "3. Analyze dominance patterns\n",
    "4. Validate Stadium classification criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from analysis.entropy_calculation import EntropyCalculator\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all collected data files\n",
    "data_dir = Path(\"../data/raw\")\n",
    "data_files = list(data_dir.glob(\"*_data.json\"))\n",
    "\n",
    "print(f\"Found {len(data_files)} data file(s):\")\n",
    "for f in data_files:\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  - {f.name} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all project data\n",
    "projects = {}\n",
    "\n",
    "for file_path in data_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        repo_name = data['repository']['full_name']\n",
    "        projects[repo_name] = data\n",
    "        print(f\"Loaded: {repo_name}\")\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(projects)} project(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Project Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "\n",
    "for repo_name, data in projects.items():\n",
    "    repo = data['repository']\n",
    "    maintainers = data['maintainers']['statistics']\n",
    "    pr_stats = data['pull_requests']['statistics']\n",
    "    issue_stats = data['issues']['statistics']\n",
    "    \n",
    "    summary_data.append({\n",
    "        'repository': repo_name,\n",
    "        'stars': repo.get('stargazers_count', 0),\n",
    "        'forks': repo.get('forks_count', 0),\n",
    "        'language': repo.get('language', 'Unknown'),\n",
    "        'contributors': len(data['contributors']),\n",
    "        'active_maintainers': maintainers.get('active_maintainers_6mo', 0),\n",
    "        'commits': len(data['recent_commits']),\n",
    "        'total_prs': pr_stats.get('total_prs', 0),\n",
    "        'merge_rate': pr_stats.get('merged_count', 0) / max(pr_stats.get('total_prs', 1), 1),\n",
    "        'avg_merge_time_hrs': pr_stats.get('avg_time_to_merge', 0),\n",
    "        'conflict_rate': pr_stats.get('conflict_rate', 0),\n",
    "        'total_issues': issue_stats.get('total_issues', 0),\n",
    "        'avg_close_time_hrs': issue_stats.get('avg_time_to_close', 0),\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Contributor Entropy\n",
    "\n",
    "**Shannon Entropy** measures the distribution of contributions:\n",
    "- **Low entropy** → Concentrated contributions (few dominant contributors) → Stadium characteristic\n",
    "- **High entropy** → Distributed contributions (many equal contributors) → Federation characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize entropy calculator\n",
    "entropy_calc = EntropyCalculator()\n",
    "\n",
    "# Calculate entropy for each project\n",
    "entropy_results = []\n",
    "\n",
    "for repo_name, data in projects.items():\n",
    "    contributors = data['contributors']\n",
    "    \n",
    "    if len(contributors) > 0:\n",
    "        # Calculate contributor entropy\n",
    "        entropy, normalized_entropy = entropy_calc.contributor_entropy(contributors)\n",
    "        \n",
    "        # Calculate dominance metrics\n",
    "        total_contributions = sum(c['contributions'] for c in contributors)\n",
    "        top_contributor = contributors[0]\n",
    "        top_2_contributions = sum(c['contributions'] for c in contributors[:2])\n",
    "        \n",
    "        entropy_results.append({\n",
    "            'repository': repo_name,\n",
    "            'entropy': entropy,\n",
    "            'normalized_entropy': normalized_entropy,\n",
    "            'max_possible_entropy': np.log2(len(contributors)),\n",
    "            'top_contributor': top_contributor['login'],\n",
    "            'top_contributor_pct': top_contributor['contributions'] / total_contributions * 100,\n",
    "            'top_2_pct': top_2_contributions / total_contributions * 100,\n",
    "            'gini_coefficient': entropy_calc.gini_coefficient([c['contributions'] for c in contributors])\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{repo_name}:\")\n",
    "        print(f\"  Shannon Entropy: {entropy:.3f} bits\")\n",
    "        print(f\"  Normalized Entropy: {normalized_entropy:.3f} (0=concentrated, 1=uniform)\")\n",
    "        print(f\"  Top Contributor: {top_contributor['login']} ({top_contributor['contributions'] / total_contributions * 100:.1f}%)\")\n",
    "\n",
    "df_entropy = pd.DataFrame(entropy_results)\n",
    "df_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Contribution Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contribution distribution for each project\n",
    "for repo_name, data in projects.items():\n",
    "    contributors = data['contributors'][:20]  # Top 20\n",
    "    \n",
    "    if len(contributors) == 0:\n",
    "        continue\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart of top contributors\n",
    "    names = [c['login'][:15] for c in contributors]\n",
    "    contributions = [c['contributions'] for c in contributors]\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    bars = ax1.barh(names[::-1], contributions[::-1], color='steelblue')\n",
    "    ax1.set_xlabel('Contributions')\n",
    "    ax1.set_title(f'{repo_name} - Top 20 Contributors')\n",
    "    \n",
    "    # Highlight top contributor\n",
    "    bars[-1].set_color('coral')\n",
    "    \n",
    "    # Cumulative contribution curve (Lorenz-like)\n",
    "    all_contributors = data['contributors']\n",
    "    all_contributions = sorted([c['contributions'] for c in all_contributors], reverse=True)\n",
    "    cumulative = np.cumsum(all_contributions) / sum(all_contributions) * 100\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(range(1, len(cumulative) + 1), cumulative, 'b-', linewidth=2, label='Actual')\n",
    "    ax2.plot([1, len(cumulative)], [0, 100], 'r--', alpha=0.5, label='Perfect equality')\n",
    "    ax2.fill_between(range(1, len(cumulative) + 1), cumulative, alpha=0.3)\n",
    "    ax2.set_xlabel('Number of Contributors')\n",
    "    ax2.set_ylabel('Cumulative % of Contributions')\n",
    "    ax2.set_title(f'{repo_name} - Contribution Concentration')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlim(1, min(50, len(cumulative)))\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    # Add annotation for key percentages\n",
    "    for threshold in [50, 80, 90]:\n",
    "        idx = np.searchsorted(cumulative, threshold)\n",
    "        if idx < len(cumulative):\n",
    "            ax2.axhline(y=threshold, color='gray', linestyle=':', alpha=0.5)\n",
    "            ax2.annotate(f'{threshold}% by {idx+1} contributors', \n",
    "                        xy=(idx+1, threshold), fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stadium Classification Analysis\n",
    "\n",
    "Based on our research framework, a **Stadium project** exhibits:\n",
    "- Low normalized entropy (< 0.5)\n",
    "- High top contributor dominance (> 40%)\n",
    "- Few active maintainers (≤ 3, or high concentration despite more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_project(row):\n",
    "    \"\"\"Classify project based on entropy and dominance metrics.\"\"\"\n",
    "    \n",
    "    # Stadium indicators\n",
    "    low_entropy = row['normalized_entropy'] < 0.5\n",
    "    high_dominance = row['top_contributor_pct'] > 40\n",
    "    high_top2_dominance = row['top_2_pct'] > 60\n",
    "    high_gini = row['gini_coefficient'] > 0.7\n",
    "    \n",
    "    # Count Stadium indicators\n",
    "    stadium_score = sum([low_entropy, high_dominance, high_top2_dominance, high_gini])\n",
    "    \n",
    "    if stadium_score >= 3:\n",
    "        return 'Stadium (Strong)'\n",
    "    elif stadium_score >= 2:\n",
    "        return 'Stadium (Likely)'\n",
    "    elif stadium_score >= 1:\n",
    "        return 'Hybrid/Uncertain'\n",
    "    else:\n",
    "        return 'Federation/Club'\n",
    "\n",
    "if len(df_entropy) > 0:\n",
    "    df_entropy['classification'] = df_entropy.apply(classify_project, axis=1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROJECT CLASSIFICATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for _, row in df_entropy.iterrows():\n",
    "        print(f\"\\n{row['repository']}:\")\n",
    "        print(f\"  Classification: {row['classification']}\")\n",
    "        print(f\"  Normalized Entropy: {row['normalized_entropy']:.3f}\")\n",
    "        print(f\"  Top Contributor: {row['top_contributor']} ({row['top_contributor_pct']:.1f}%)\")\n",
    "        print(f\"  Top 2 Contributors: {row['top_2_pct']:.1f}%\")\n",
    "        print(f\"  Gini Coefficient: {row['gini_coefficient']:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Governance Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze governance files presence\n",
    "governance_data = []\n",
    "\n",
    "for repo_name, data in projects.items():\n",
    "    gov_files = data.get('governance_files', {})\n",
    "    governance_data.append({\n",
    "        'repository': repo_name,\n",
    "        'GOVERNANCE.md': gov_files.get('GOVERNANCE.md', False),\n",
    "        'CONTRIBUTING.md': gov_files.get('CONTRIBUTING.md', False),\n",
    "        'CODE_OF_CONDUCT.md': gov_files.get('CODE_OF_CONDUCT.md', False),\n",
    "        'SECURITY.md': gov_files.get('SECURITY.md', False),\n",
    "        'MAINTAINERS.md': gov_files.get('MAINTAINERS.md', False),\n",
    "        'CODEOWNERS': gov_files.get('.github/CODEOWNERS', False),\n",
    "    })\n",
    "\n",
    "df_governance = pd.DataFrame(governance_data)\n",
    "\n",
    "print(\"Governance Files Present:\")\n",
    "print(\"─\" * 60)\n",
    "for _, row in df_governance.iterrows():\n",
    "    print(f\"\\n{row['repository']}:\")\n",
    "    for col in df_governance.columns[1:]:\n",
    "        status = \"✓\" if row[col] else \"✗\"\n",
    "        print(f\"  {status} {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all analysis into single DataFrame\n",
    "if len(df_entropy) > 0 and len(df_summary) > 0:\n",
    "    df_analysis = df_summary.merge(df_entropy, on='repository')\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = Path(\"../data/processed/analysis_results.csv\")\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_analysis.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"✅ Analysis saved to: {output_path}\")\n",
    "    \n",
    "    # Display final table\n",
    "    display_cols = ['repository', 'stars', 'contributors', 'active_maintainers', \n",
    "                    'normalized_entropy', 'top_contributor_pct', 'gini_coefficient', \n",
    "                    'classification']\n",
    "    df_analysis[display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Collect more Stadium candidates** from `data/stadium_candidates.md`\n",
    "2. **Compare with Federation/Club projects** for statistical validation\n",
    "3. **Run hypothesis tests** (H1-H6) once sample sizes are sufficient\n",
    "4. **Temporal entropy analysis** - how entropy changes over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Categories)",
   "language": "python",
   "name": "categories-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
