{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 04 - VSM Mapping: Viable System Model Analysis\n",
    "\n",
    "Map OSS project metrics to Stafford Beer's Viable System Model (VSM) subsystems.\n",
    "\n",
    "**VSM Subsystems:**\n",
    "- **S1 (Operations)**: Primary activities - code contributions, commits, releases\n",
    "- **S2 (Coordination)**: Anti-oscillatory mechanisms - CI/CD, coding standards, PR reviews\n",
    "- **S3 (Control)**: Resource allocation - maintainer decisions, issue triage\n",
    "- **S4 (Intelligence)**: Environmental scanning - roadmaps, community feedback, security alerts\n",
    "- **S5 (Policy)**: Identity and governance - GOVERNANCE.md, CODE_OF_CONDUCT, core values\n",
    "\n",
    "**Research Questions:**\n",
    "- How do Stadium projects differ from Federation/Club in VSM structure?\n",
    "- Which subsystems are under-developed in vulnerable projects?\n",
    "- Can VSM analysis predict project sustainability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Circle, FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "from analysis.entropy_calculation import EntropyCalculator\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Load Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all collected project data\n",
    "data_dir = Path(\"../data/raw\")\n",
    "projects = {}\n",
    "\n",
    "for file_path in data_dir.glob(\"*_data.json\"):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        repo_name = data['repository']['full_name']\n",
    "        projects[repo_name] = data\n",
    "\n",
    "print(f\"Loaded {len(projects)} projects:\")\n",
    "for name in projects:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Define VSM Metric Mapping\n",
    "\n",
    "Map GitHub metrics to VSM subsystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSMMapper:\n",
    "    \"\"\"\n",
    "    Map OSS project metrics to Viable System Model subsystems.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.entropy_calc = EntropyCalculator()\n",
    "    \n",
    "    def calculate_s1_operations(self, project_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        S1 (Operations): Primary productive activities.\n",
    "        \n",
    "        Metrics:\n",
    "        - Commit frequency and volume\n",
    "        - Contributor activity\n",
    "        - Release cadence\n",
    "        \"\"\"\n",
    "        commits = project_data.get('recent_commits', [])\n",
    "        contributors = project_data.get('contributors', [])\n",
    "        repo = project_data.get('repository', {})\n",
    "        \n",
    "        # Commit activity\n",
    "        commit_count = len(commits)\n",
    "        \n",
    "        # Unique committers in recent period\n",
    "        committers = set()\n",
    "        for c in commits:\n",
    "            if c.get('author'):\n",
    "                committers.add(c['author'])\n",
    "        \n",
    "        # Contributor entropy (distribution of work)\n",
    "        entropy, normalized = self.entropy_calc.contributor_entropy(contributors)\n",
    "        \n",
    "        # Code changes volume\n",
    "        total_additions = sum(c.get('additions', 0) for c in commits)\n",
    "        total_deletions = sum(c.get('deletions', 0) for c in commits)\n",
    "        \n",
    "        return {\n",
    "            'commit_count': commit_count,\n",
    "            'unique_committers': len(committers),\n",
    "            'total_contributors': len(contributors),\n",
    "            'contributor_entropy': normalized,\n",
    "            'code_additions': total_additions,\n",
    "            'code_deletions': total_deletions,\n",
    "            'code_churn': total_additions + total_deletions,\n",
    "            # S1 Health Score (0-100)\n",
    "            's1_score': min(100, (commit_count / 365 * 50) + (len(committers) * 5))\n",
    "        }\n",
    "    \n",
    "    def calculate_s2_coordination(self, project_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        S2 (Coordination): Anti-oscillatory mechanisms.\n",
    "        \n",
    "        Metrics:\n",
    "        - PR review process\n",
    "        - CI/CD presence\n",
    "        - Coding standards enforcement\n",
    "        \"\"\"\n",
    "        prs = project_data.get('pull_requests', {}).get('pull_requests', [])\n",
    "        pr_stats = project_data.get('pull_requests', {}).get('statistics', {})\n",
    "        governance = project_data.get('governance_files', {})\n",
    "        \n",
    "        # PR review metrics\n",
    "        reviewed_prs = sum(1 for pr in prs if pr.get('review_count', 0) > 0)\n",
    "        review_rate = reviewed_prs / len(prs) if prs else 0\n",
    "        \n",
    "        # Merge time consistency (lower is better coordination)\n",
    "        avg_merge_time = pr_stats.get('avg_time_to_merge', 0)\n",
    "        \n",
    "        # Standards presence\n",
    "        has_contributing = governance.get('CONTRIBUTING.md', False)\n",
    "        has_codeowners = governance.get('.github/CODEOWNERS', False)\n",
    "        \n",
    "        # Calculate coordination score\n",
    "        coord_score = 0\n",
    "        coord_score += review_rate * 40  # 40 points for review coverage\n",
    "        coord_score += 20 if has_contributing else 0\n",
    "        coord_score += 20 if has_codeowners else 0\n",
    "        coord_score += 20 if avg_merge_time < 72 else (10 if avg_merge_time < 168 else 0)\n",
    "        \n",
    "        return {\n",
    "            'total_prs': len(prs),\n",
    "            'reviewed_prs': reviewed_prs,\n",
    "            'review_rate': review_rate,\n",
    "            'avg_merge_time_hrs': avg_merge_time,\n",
    "            'has_contributing_guide': has_contributing,\n",
    "            'has_codeowners': has_codeowners,\n",
    "            's2_score': min(100, coord_score)\n",
    "        }\n",
    "    \n",
    "    def calculate_s3_control(self, project_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        S3 (Control): Internal resource allocation and optimization.\n",
    "        \n",
    "        Metrics:\n",
    "        - Maintainer activity and responsiveness\n",
    "        - Issue management\n",
    "        - Decision-making patterns\n",
    "        \"\"\"\n",
    "        maintainers = project_data.get('maintainers', {}).get('statistics', {})\n",
    "        issues = project_data.get('issues', {}).get('issues', [])\n",
    "        issue_stats = project_data.get('issues', {}).get('statistics', {})\n",
    "        \n",
    "        active_maintainers = maintainers.get('active_maintainers_6mo', 0)\n",
    "        avg_close_time = issue_stats.get('avg_time_to_close', 0)\n",
    "        \n",
    "        # Issue triage (labeled issues)\n",
    "        labeled_issues = sum(1 for i in issues if i.get('labels'))\n",
    "        label_rate = labeled_issues / len(issues) if issues else 0\n",
    "        \n",
    "        # Control concentration (Gini of contributions)\n",
    "        contributors = project_data.get('contributors', [])\n",
    "        contributions = [c.get('contributions', 0) for c in contributors]\n",
    "        gini = self.entropy_calc.gini_coefficient(contributions)\n",
    "        \n",
    "        # Calculate control score\n",
    "        control_score = 0\n",
    "        control_score += min(30, active_maintainers * 10)  # Up to 30 for maintainers\n",
    "        control_score += 30 if avg_close_time < 168 else (15 if avg_close_time < 720 else 0)\n",
    "        control_score += label_rate * 20\n",
    "        control_score += (1 - gini) * 20  # Lower Gini = better distributed control\n",
    "        \n",
    "        return {\n",
    "            'active_maintainers': active_maintainers,\n",
    "            'total_issues': len(issues),\n",
    "            'avg_close_time_hrs': avg_close_time,\n",
    "            'label_rate': label_rate,\n",
    "            'control_concentration': gini,\n",
    "            's3_score': min(100, control_score)\n",
    "        }\n",
    "    \n",
    "    def calculate_s4_intelligence(self, project_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        S4 (Intelligence): Environmental scanning and adaptation.\n",
    "        \n",
    "        Metrics:\n",
    "        - External engagement (forks, community)\n",
    "        - Security responsiveness\n",
    "        - Ecosystem awareness\n",
    "        \"\"\"\n",
    "        repo = project_data.get('repository', {})\n",
    "        governance = project_data.get('governance_files', {})\n",
    "        \n",
    "        stars = repo.get('stargazers_count', 0)\n",
    "        forks = repo.get('forks_count', 0)\n",
    "        watchers = repo.get('watchers_count', 0)\n",
    "        \n",
    "        # Fork ratio indicates external adoption/adaptation\n",
    "        fork_ratio = forks / stars if stars > 0 else 0\n",
    "        \n",
    "        # Security awareness\n",
    "        has_security = governance.get('SECURITY.md', False)\n",
    "        \n",
    "        # Calculate intelligence score\n",
    "        intel_score = 0\n",
    "        intel_score += min(30, np.log10(stars + 1) * 10)  # Logarithmic star impact\n",
    "        intel_score += min(20, fork_ratio * 100)  # Fork engagement\n",
    "        intel_score += 30 if has_security else 0\n",
    "        intel_score += min(20, np.log10(watchers + 1) * 10)\n",
    "        \n",
    "        return {\n",
    "            'stars': stars,\n",
    "            'forks': forks,\n",
    "            'watchers': watchers,\n",
    "            'fork_ratio': fork_ratio,\n",
    "            'has_security_policy': has_security,\n",
    "            's4_score': min(100, intel_score)\n",
    "        }\n",
    "    \n",
    "    def calculate_s5_policy(self, project_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        S5 (Policy): Identity, values, and ultimate authority.\n",
    "        \n",
    "        Metrics:\n",
    "        - Governance documentation\n",
    "        - Code of conduct\n",
    "        - Decision-making transparency\n",
    "        \"\"\"\n",
    "        governance = project_data.get('governance_files', {})\n",
    "        repo = project_data.get('repository', {})\n",
    "        \n",
    "        has_governance = governance.get('GOVERNANCE.md', False)\n",
    "        has_coc = governance.get('CODE_OF_CONDUCT.md', False)\n",
    "        has_maintainers = governance.get('MAINTAINERS.md', False) or governance.get('CONTRIBUTORS.md', False)\n",
    "        has_license = repo.get('license') is not None\n",
    "        \n",
    "        # Governance completeness\n",
    "        gov_files_count = sum([\n",
    "            has_governance, has_coc, has_maintainers, has_license,\n",
    "            governance.get('CONTRIBUTING.md', False),\n",
    "            governance.get('SECURITY.md', False)\n",
    "        ])\n",
    "        \n",
    "        # Calculate policy score\n",
    "        policy_score = 0\n",
    "        policy_score += 25 if has_governance else 0\n",
    "        policy_score += 25 if has_coc else 0\n",
    "        policy_score += 20 if has_maintainers else 0\n",
    "        policy_score += 15 if has_license else 0\n",
    "        policy_score += gov_files_count * 2.5  # Bonus for completeness\n",
    "        \n",
    "        return {\n",
    "            'has_governance': has_governance,\n",
    "            'has_code_of_conduct': has_coc,\n",
    "            'has_maintainers_file': has_maintainers,\n",
    "            'has_license': has_license,\n",
    "            'governance_completeness': gov_files_count / 6,\n",
    "            's5_score': min(100, policy_score)\n",
    "        }\n",
    "    \n",
    "    def calculate_full_vsm(self, project_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Calculate complete VSM profile for a project.\n",
    "        \"\"\"\n",
    "        s1 = self.calculate_s1_operations(project_data)\n",
    "        s2 = self.calculate_s2_coordination(project_data)\n",
    "        s3 = self.calculate_s3_control(project_data)\n",
    "        s4 = self.calculate_s4_intelligence(project_data)\n",
    "        s5 = self.calculate_s5_policy(project_data)\n",
    "        \n",
    "        # Overall viability score (weighted average)\n",
    "        viability_score = (\n",
    "            s1['s1_score'] * 0.25 +\n",
    "            s2['s2_score'] * 0.20 +\n",
    "            s3['s3_score'] * 0.25 +\n",
    "            s4['s4_score'] * 0.15 +\n",
    "            s5['s5_score'] * 0.15\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'S1_Operations': s1,\n",
    "            'S2_Coordination': s2,\n",
    "            'S3_Control': s3,\n",
    "            'S4_Intelligence': s4,\n",
    "            'S5_Policy': s5,\n",
    "            'viability_score': viability_score,\n",
    "            'subsystem_scores': {\n",
    "                'S1': s1['s1_score'],\n",
    "                'S2': s2['s2_score'],\n",
    "                'S3': s3['s3_score'],\n",
    "                'S4': s4['s4_score'],\n",
    "                'S5': s5['s5_score']\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Initialize mapper\n",
    "vsm_mapper = VSMMapper()\n",
    "print(\"✅ VSM Mapper initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Calculate VSM Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VSM profiles for all projects\n",
    "vsm_profiles = {}\n",
    "\n",
    "for repo_name, data in projects.items():\n",
    "    vsm_profiles[repo_name] = vsm_mapper.calculate_full_vsm(data)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{repo_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Viability Score: {vsm_profiles[repo_name]['viability_score']:.1f}/100\")\n",
    "    print(f\"\\nSubsystem Scores:\")\n",
    "    for subsystem, score in vsm_profiles[repo_name]['subsystem_scores'].items():\n",
    "        bar = '█' * int(score / 5) + '░' * (20 - int(score / 5))\n",
    "        print(f\"  {subsystem}: {bar} {score:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. VSM Radar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vsm_radar(vsm_profile: dict, title: str, ax=None):\n",
    "    \"\"\"\n",
    "    Create radar chart for VSM subsystem scores.\n",
    "    \"\"\"\n",
    "    categories = ['S1\\nOperations', 'S2\\nCoordination', 'S3\\nControl', \n",
    "                  'S4\\nIntelligence', 'S5\\nPolicy']\n",
    "    scores = [vsm_profile['subsystem_scores'][f'S{i}'] for i in range(1, 6)]\n",
    "    \n",
    "    # Close the radar chart\n",
    "    scores += scores[:1]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # Plot data\n",
    "    ax.plot(angles, scores, 'o-', linewidth=2, color='steelblue')\n",
    "    ax.fill(angles, scores, alpha=0.25, color='steelblue')\n",
    "    \n",
    "    # Set category labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, size=10)\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_yticks([20, 40, 60, 80, 100])\n",
    "    ax.set_yticklabels(['20', '40', '60', '80', '100'], size=8)\n",
    "    \n",
    "    ax.set_title(f\"{title}\\nViability: {vsm_profile['viability_score']:.1f}/100\", \n",
    "                 size=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# Create radar charts for all projects\n",
    "n_projects = len(vsm_profiles)\n",
    "cols = min(3, n_projects)\n",
    "rows = (n_projects + cols - 1) // cols\n",
    "\n",
    "fig = plt.figure(figsize=(6 * cols, 6 * rows))\n",
    "\n",
    "for i, (repo_name, profile) in enumerate(vsm_profiles.items()):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1, polar=True)\n",
    "    plot_vsm_radar(profile, repo_name.split('/')[-1], ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/diagrams/vsm_radar_charts.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Radar charts saved to docs/diagrams/vsm_radar_charts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. VSM Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "\n",
    "for repo_name, profile in vsm_profiles.items():\n",
    "    row = {\n",
    "        'repository': repo_name,\n",
    "        'viability_score': profile['viability_score'],\n",
    "        **profile['subsystem_scores']\n",
    "    }\n",
    "    \n",
    "    # Add classification\n",
    "    entropy_calc = EntropyCalculator()\n",
    "    classification = entropy_calc.classify_project(projects[repo_name]['contributors'])\n",
    "    row['classification'] = classification['classification']\n",
    "    row['stadium_score'] = classification['stadium_score']\n",
    "    \n",
    "    comparison_data.append(row)\n",
    "\n",
    "df_vsm = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Display sorted by viability\n",
    "print(\"\\nVSM Comparison (sorted by viability score):\")\n",
    "print(\"=\"*80)\n",
    "display(df_vsm.sort_values('viability_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of VSM scores\n",
    "if len(df_vsm) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, len(df_vsm) * 0.8)))\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    heatmap_data = df_vsm.set_index('repository')[['S1', 'S2', 'S3', 'S4', 'S5']]\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='RdYlGn',\n",
    "                vmin=0, vmax=100, ax=ax, cbar_kws={'label': 'Score'})\n",
    "    \n",
    "    ax.set_xlabel('VSM Subsystem')\n",
    "    ax.set_ylabel('Project')\n",
    "    ax.set_title('VSM Subsystem Scores Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/diagrams/vsm_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Need more projects for comparison heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. VSM Weaknesses Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_vsm_weaknesses(vsm_profile: dict, threshold: float = 50) -> list:\n",
    "    \"\"\"\n",
    "    Identify weak subsystems (below threshold).\n",
    "    \"\"\"\n",
    "    weaknesses = []\n",
    "    subsystem_names = {\n",
    "        'S1': 'Operations (S1) - Primary productive activities',\n",
    "        'S2': 'Coordination (S2) - Anti-oscillatory mechanisms',\n",
    "        'S3': 'Control (S3) - Resource allocation',\n",
    "        'S4': 'Intelligence (S4) - Environmental scanning',\n",
    "        'S5': 'Policy (S5) - Governance and identity'\n",
    "    }\n",
    "    \n",
    "    for subsystem, score in vsm_profile['subsystem_scores'].items():\n",
    "        if score < threshold:\n",
    "            weaknesses.append({\n",
    "                'subsystem': subsystem,\n",
    "                'name': subsystem_names[subsystem],\n",
    "                'score': score,\n",
    "                'gap': threshold - score\n",
    "            })\n",
    "    \n",
    "    return sorted(weaknesses, key=lambda x: x['gap'], reverse=True)\n",
    "\n",
    "# Analyze weaknesses for each project\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VSM WEAKNESSES ANALYSIS (threshold: 50)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for repo_name, profile in vsm_profiles.items():\n",
    "    weaknesses = identify_vsm_weaknesses(profile)\n",
    "    \n",
    "    print(f\"\\n{repo_name}:\")\n",
    "    if weaknesses:\n",
    "        for w in weaknesses:\n",
    "            print(f\"  ⚠️  {w['name']}: {w['score']:.1f} (gap: {w['gap']:.1f})\")\n",
    "    else:\n",
    "        print(f\"  ✅ All subsystems above threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. VSM-Classification Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation between Stadium classification and VSM scores\n",
    "if len(df_vsm) >= 3:\n",
    "    print(\"\\nVSM Score Statistics by Classification:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for col in ['viability_score', 'S1', 'S2', 'S3', 'S4', 'S5']:\n",
    "        print(f\"\\n{col}:\")\n",
    "        stats = df_vsm.groupby('classification')[col].agg(['mean', 'std', 'count'])\n",
    "        print(stats.round(2))\n",
    "else:\n",
    "    print(\"Need more projects for classification correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VSM analysis results\n",
    "output_path = Path('../data/processed/vsm_analysis.csv')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_vsm.to_csv(output_path, index=False)\n",
    "print(f\"✅ VSM analysis saved to {output_path}\")\n",
    "\n",
    "# Save detailed profiles as JSON\n",
    "json_path = Path('../data/processed/vsm_profiles.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(vsm_profiles, f, indent=2, default=str)\n",
    "print(f\"✅ Detailed profiles saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "**Interpretation Guide:**\n",
    "- **High S1, Low S2**: Active development but poor coordination → Risk of conflicts\n",
    "- **High S3, Low S1**: Strong control but low activity → Potential stagnation\n",
    "- **Low S5**: Missing governance → Identity crisis risk\n",
    "- **Stadium + Low S5**: \"Bus factor\" risk - dependent on key maintainer\n",
    "\n",
    "**Next Steps:**\n",
    "1. Collect more projects to establish patterns\n",
    "2. Correlate VSM scores with project outcomes\n",
    "3. Develop intervention recommendations based on VSM gaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Categories)",
   "language": "python",
   "name": "categories-env"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
