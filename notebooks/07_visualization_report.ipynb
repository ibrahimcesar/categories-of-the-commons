{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Visualization & Report Generation\n",
    "\n",
    "Publication-ready figures and tables for \"Categories of the Commons\" research.\n",
    "\n",
    "## Outputs\n",
    "- Figure 1: OSS Governance Taxonomy Overview\n",
    "- Figure 2: Entropy Distribution by Category\n",
    "- Figure 3: VSM Radar Comparison\n",
    "- Figure 4: Category Theory Composition Diagram\n",
    "- Table 1: Project Classification Summary\n",
    "- Table 2: Statistical Metrics by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Publication-quality settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'font.family': 'serif',\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 14,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'savefig.pad_inches': 0.1\n",
    "})\n",
    "\n",
    "# Color palette for governance categories\n",
    "CATEGORY_COLORS = {\n",
    "    'Stadium': '#E74C3C',      # Red - high visibility, concentrated\n",
    "    'Federation': '#3498DB',   # Blue - distributed, collaborative\n",
    "    'Club': '#2ECC71',         # Green - community-focused\n",
    "    'Toy': '#9B59B6',          # Purple - experimental\n",
    "    'Hybrid': '#F39C12'        # Orange - mixed characteristics\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "FIGURES_DIR = Path('../outputs/figures')\n",
    "TABLES_DIR = Path('../outputs/tables')\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Visualization environment configured for publication output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from analysis.entropy_calculation import EntropyCalculator\n",
    "\n",
    "def load_all_project_data() -> Dict[str, Dict]:\n",
    "    \"\"\"Load all collected project data.\"\"\"\n",
    "    data_dir = Path('../data/raw')\n",
    "    projects = {}\n",
    "    \n",
    "    for json_file in data_dir.glob('*_data.json'):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                project_name = data.get('full_name', json_file.stem.replace('_data', ''))\n",
    "                projects[project_name] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {json_file}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(projects)} projects\")\n",
    "    return projects\n",
    "\n",
    "def classify_all_projects(projects: Dict[str, Dict]) -> pd.DataFrame:\n",
    "    \"\"\"Classify all projects and create summary DataFrame.\"\"\"\n",
    "    calculator = EntropyCalculator()\n",
    "    results = []\n",
    "    \n",
    "    for name, data in projects.items():\n",
    "        contributors = data.get('contributors', [])\n",
    "        classification = calculator.classify_project(contributors)\n",
    "        \n",
    "        # Determine primary category\n",
    "        class_label = classification['classification']\n",
    "        if 'Stadium' in class_label:\n",
    "            category = 'Stadium'\n",
    "        elif 'Federation' in class_label or 'Club' in class_label:\n",
    "            category = 'Federation'\n",
    "        elif 'Hybrid' in class_label or 'Uncertain' in class_label:\n",
    "            category = 'Hybrid'\n",
    "        else:\n",
    "            category = 'Unknown'\n",
    "        \n",
    "        metrics = classification.get('metrics', {})\n",
    "        results.append({\n",
    "            'project': name,\n",
    "            'classification': class_label,\n",
    "            'category': category,\n",
    "            'confidence': classification.get('confidence', 0),\n",
    "            'stadium_score': classification.get('stadium_score', 0),\n",
    "            'entropy': metrics.get('entropy', 0),\n",
    "            'normalized_entropy': metrics.get('normalized_entropy', 0),\n",
    "            'gini': metrics.get('gini_coefficient', 0),\n",
    "            'top1_pct': metrics.get('top_contributor_pct', 0),\n",
    "            'contributors': metrics.get('total_contributors', 0),\n",
    "            'stars': data.get('stargazers_count', 0),\n",
    "            'forks': data.get('forks_count', 0),\n",
    "            'open_issues': data.get('open_issues_count', 0)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Load and classify\n",
    "projects = load_all_project_data()\n",
    "df = classify_all_projects(projects)\n",
    "df.sort_values('stars', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: OSS Governance Taxonomy Overview\n",
    "\n",
    "A comprehensive visualization showing the relationship between Asparouhova's taxonomy,\n",
    "entropy measures, and the projects in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_taxonomy_figure(df: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"Create taxonomy overview figure with quadrant plot.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Left: Entropy vs Gini scatter with quadrants\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Draw quadrant backgrounds\n",
    "    ax1.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax1.axvline(x=0.6, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add quadrant labels\n",
    "    ax1.text(0.3, 0.9, 'STADIUM\\n(High inequality,\\nlow diversity)', \n",
    "             ha='center', va='center', fontsize=9, alpha=0.7,\n",
    "             bbox=dict(boxstyle='round', facecolor='#E74C3C', alpha=0.2))\n",
    "    ax1.text(0.8, 0.9, 'HYBRID\\n(High inequality,\\nhigh diversity)', \n",
    "             ha='center', va='center', fontsize=9, alpha=0.7,\n",
    "             bbox=dict(boxstyle='round', facecolor='#F39C12', alpha=0.2))\n",
    "    ax1.text(0.3, 0.6, 'CLUB\\n(Low inequality,\\nlow diversity)', \n",
    "             ha='center', va='center', fontsize=9, alpha=0.7,\n",
    "             bbox=dict(boxstyle='round', facecolor='#2ECC71', alpha=0.2))\n",
    "    ax1.text(0.8, 0.6, 'FEDERATION\\n(Low inequality,\\nhigh diversity)', \n",
    "             ha='center', va='center', fontsize=9, alpha=0.7,\n",
    "             bbox=dict(boxstyle='round', facecolor='#3498DB', alpha=0.2))\n",
    "    \n",
    "    # Plot projects\n",
    "    for category in df['category'].unique():\n",
    "        subset = df[df['category'] == category]\n",
    "        color = CATEGORY_COLORS.get(category, 'gray')\n",
    "        ax1.scatter(subset['normalized_entropy'], subset['gini'],\n",
    "                   c=color, label=category, s=100, alpha=0.7, edgecolors='white')\n",
    "        \n",
    "        # Add project labels\n",
    "        for _, row in subset.iterrows():\n",
    "            short_name = row['project'].split('/')[-1][:10]\n",
    "            ax1.annotate(short_name, (row['normalized_entropy'], row['gini']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel('Normalized Entropy (diversity)')\n",
    "    ax1.set_ylabel('Gini Coefficient (inequality)')\n",
    "    ax1.set_title('(a) Governance Classification Space')\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_ylim(0.5, 1)\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right: Category distribution bar chart\n",
    "    ax2 = axes[1]\n",
    "    category_counts = df['category'].value_counts()\n",
    "    colors = [CATEGORY_COLORS.get(cat, 'gray') for cat in category_counts.index]\n",
    "    bars = ax2.bar(category_counts.index, category_counts.values, color=colors, alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Governance Category')\n",
    "    ax2.set_ylabel('Number of Projects')\n",
    "    ax2.set_title('(b) Distribution of Classifications')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, category_counts.values):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                str(count), ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if len(df) > 0:\n",
    "    fig1 = create_taxonomy_figure(df)\n",
    "    fig1.savefig(FIGURES_DIR / 'fig1_taxonomy_overview.png')\n",
    "    fig1.savefig(FIGURES_DIR / 'fig1_taxonomy_overview.pdf')\n",
    "    print(f\"Saved Figure 1 to {FIGURES_DIR}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No project data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Entropy Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entropy_figure(df: pd.DataFrame, projects: Dict) -> plt.Figure:\n",
    "    \"\"\"Create entropy distribution visualization.\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    gs = GridSpec(2, 2, figure=fig, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # (a) Entropy histogram by category\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    for category in df['category'].unique():\n",
    "        subset = df[df['category'] == category]['entropy']\n",
    "        if len(subset) > 0:\n",
    "            ax1.hist(subset, bins=10, alpha=0.6, label=category,\n",
    "                    color=CATEGORY_COLORS.get(category, 'gray'))\n",
    "    ax1.set_xlabel('Shannon Entropy (bits)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('(a) Entropy Distribution by Category')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # (b) Box plot comparison\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    categories = df['category'].unique()\n",
    "    box_data = [df[df['category'] == cat]['normalized_entropy'].dropna() for cat in categories]\n",
    "    bp = ax2.boxplot(box_data, labels=categories, patch_artist=True)\n",
    "    for patch, cat in zip(bp['boxes'], categories):\n",
    "        patch.set_facecolor(CATEGORY_COLORS.get(cat, 'gray'))\n",
    "        patch.set_alpha(0.6)\n",
    "    ax2.set_ylabel('Normalized Entropy')\n",
    "    ax2.set_title('(b) Entropy Spread by Category')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # (c) Top contributor % vs entropy\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    for category in df['category'].unique():\n",
    "        subset = df[df['category'] == category]\n",
    "        ax3.scatter(subset['top1_pct'], subset['entropy'],\n",
    "                   c=CATEGORY_COLORS.get(category, 'gray'),\n",
    "                   label=category, s=80, alpha=0.7)\n",
    "    ax3.set_xlabel('Top Contributor %')\n",
    "    ax3.set_ylabel('Shannon Entropy (bits)')\n",
    "    ax3.set_title('(c) Dominance vs Entropy')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # (d) Contributor Lorenz curves for select projects\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # Plot perfect equality line\n",
    "    ax4.plot([0, 1], [0, 1], 'k--', label='Perfect Equality', alpha=0.5)\n",
    "    \n",
    "    # Plot Lorenz curves for up to 5 projects\n",
    "    for project_name in list(projects.keys())[:5]:\n",
    "        data = projects[project_name]\n",
    "        contributors = data.get('contributors', [])\n",
    "        if not contributors:\n",
    "            continue\n",
    "            \n",
    "        contributions = sorted([c.get('contributions', 0) for c in contributors], reverse=True)\n",
    "        total = sum(contributions)\n",
    "        if total == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate cumulative percentages\n",
    "        cumulative = np.cumsum(contributions) / total\n",
    "        x = np.arange(1, len(cumulative) + 1) / len(cumulative)\n",
    "        \n",
    "        short_name = project_name.split('/')[-1]\n",
    "        ax4.plot(x, cumulative, label=short_name, linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax4.set_xlabel('Cumulative % of Contributors')\n",
    "    ax4.set_ylabel('Cumulative % of Contributions')\n",
    "    ax4.set_title('(d) Lorenz Curves (Contribution Inequality)')\n",
    "    ax4.legend(loc='lower right', fontsize=8)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(0, 1)\n",
    "    ax4.set_ylim(0, 1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if len(df) > 0:\n",
    "    fig2 = create_entropy_figure(df, projects)\n",
    "    fig2.savefig(FIGURES_DIR / 'fig2_entropy_analysis.png')\n",
    "    fig2.savefig(FIGURES_DIR / 'fig2_entropy_analysis.pdf')\n",
    "    print(f\"Saved Figure 2 to {FIGURES_DIR}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No project data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: VSM Radar Comparison\n",
    "\n",
    "Comparing projects across Viable System Model dimensions (S1-S5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vsm_metrics(project_data: Dict) -> Dict[str, float]:\n",
    "    \"\"\"Calculate VSM S1-S5 metrics for a project.\"\"\"\n",
    "    contributors = project_data.get('contributors', [])\n",
    "    \n",
    "    # S1: Operations (commit activity)\n",
    "    recent_commits = len(project_data.get('recent_commits', []))\n",
    "    s1 = min(recent_commits / 100, 1.0)  # Normalize to 0-1\n",
    "    \n",
    "    # S2: Coordination (issues/PR management)\n",
    "    open_issues = project_data.get('open_issues_count', 0)\n",
    "    closed_issues = project_data.get('closed_issues_count', 0)\n",
    "    total_issues = open_issues + closed_issues\n",
    "    s2 = closed_issues / total_issues if total_issues > 0 else 0.5\n",
    "    \n",
    "    # S3: Control (contributor distribution)\n",
    "    if contributors:\n",
    "        contributions = [c.get('contributions', 0) for c in contributors]\n",
    "        total = sum(contributions)\n",
    "        top_pct = contributions[0] / total if total > 0 else 0\n",
    "        s3 = 1 - top_pct  # Lower concentration = better control distribution\n",
    "    else:\n",
    "        s3 = 0.5\n",
    "    \n",
    "    # S4: Intelligence (documentation, community)\n",
    "    has_wiki = 1.0 if project_data.get('has_wiki', False) else 0.0\n",
    "    has_discussions = 1.0 if project_data.get('has_discussions', False) else 0.0\n",
    "    s4 = (has_wiki + has_discussions) / 2\n",
    "    \n",
    "    # S5: Identity (stars, forks as community recognition)\n",
    "    stars = project_data.get('stargazers_count', 0)\n",
    "    forks = project_data.get('forks_count', 0)\n",
    "    s5 = min((stars + forks * 2) / 100000, 1.0)  # Normalize\n",
    "    \n",
    "    return {'S1': s1, 'S2': s2, 'S3': s3, 'S4': s4, 'S5': s5}\n",
    "\n",
    "def create_vsm_radar(projects: Dict, max_projects: int = 6) -> plt.Figure:\n",
    "    \"\"\"Create VSM radar chart comparing projects.\"\"\"\n",
    "    categories = ['S1\\nOperations', 'S2\\nCoordination', 'S3\\nControl', \n",
    "                  'S4\\nIntelligence', 'S5\\nIdentity']\n",
    "    N = len(categories)\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    project_names = list(projects.keys())[:max_projects]\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(project_names)))\n",
    "    \n",
    "    for idx, project_name in enumerate(project_names):\n",
    "        vsm = calculate_vsm_metrics(projects[project_name])\n",
    "        values = [vsm['S1'], vsm['S2'], vsm['S3'], vsm['S4'], vsm['S5']]\n",
    "        values += values[:1]  # Complete the loop\n",
    "        \n",
    "        short_name = project_name.split('/')[-1]\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=short_name, color=colors[idx])\n",
    "        ax.fill(angles, values, alpha=0.15, color=colors[idx])\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, size=11)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('VSM Subsystem Comparison', size=14, y=1.08)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if len(projects) > 0:\n",
    "    fig3 = create_vsm_radar(projects)\n",
    "    fig3.savefig(FIGURES_DIR / 'fig3_vsm_radar.png')\n",
    "    fig3.savefig(FIGURES_DIR / 'fig3_vsm_radar.pdf')\n",
    "    print(f\"Saved Figure 3 to {FIGURES_DIR}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No project data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Theoretical Framework Diagram\n",
    "\n",
    "Illustrating the category-theoretic composition of governance models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_framework_diagram() -> plt.Figure:\n",
    "    \"\"\"Create theoretical framework composition diagram.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    ax.set_xlim(0, 14)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Define boxes for each theoretical component\n",
    "    boxes = {\n",
    "        'GitHub Data': (1, 7.5, 2.5, 1.5, '#E8F4F8'),\n",
    "        'Shannon Entropy': (5, 7.5, 2.5, 1.5, '#FFF3E0'),\n",
    "        'VSM S1-S5': (9, 7.5, 2.5, 1.5, '#E8F5E9'),\n",
    "        'Asparouhova\\nTaxonomy': (1, 4, 2.5, 1.5, '#FCE4EC'),\n",
    "        'Ostrom\\nPrinciples': (5, 4, 2.5, 1.5, '#F3E5F5'),\n",
    "        'Category\\nTheory': (9, 4, 2.5, 1.5, '#E3F2FD'),\n",
    "        'Governance\\nClassification': (5, 0.5, 3, 2, '#FFEBEE')\n",
    "    }\n",
    "    \n",
    "    # Draw boxes\n",
    "    for name, (x, y, w, h, color) in boxes.items():\n",
    "        rect = mpatches.FancyBboxPatch((x, y), w, h,\n",
    "                                        boxstyle=\"round,pad=0.05\",\n",
    "                                        facecolor=color,\n",
    "                                        edgecolor='black',\n",
    "                                        linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x + w/2, y + h/2, name, ha='center', va='center',\n",
    "               fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Draw arrows with labels\n",
    "    arrow_style = dict(arrowstyle='->', color='#333', lw=2,\n",
    "                       connectionstyle='arc3,rad=0')\n",
    "    \n",
    "    # Vertical arrows (data flow)\n",
    "    arrows = [\n",
    "        ((2.25, 7.5), (2.25, 5.5), 'collect'),\n",
    "        ((6.25, 7.5), (6.25, 5.5), 'calculate'),\n",
    "        ((10.25, 7.5), (10.25, 5.5), 'map'),\n",
    "        ((2.25, 4), (5, 2), 'categorize'),\n",
    "        ((6.25, 4), (6.5, 2.5), 'validate'),\n",
    "        ((10.25, 4), (8, 2), 'formalize'),\n",
    "    ]\n",
    "    \n",
    "    for (x1, y1), (x2, y2), label in arrows:\n",
    "        ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                   arrowprops=arrow_style)\n",
    "        mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "        ax.text(mid_x + 0.3, mid_y, label, fontsize=9, style='italic', alpha=0.8)\n",
    "    \n",
    "    # Add title and labels\n",
    "    ax.text(7, 9.5, 'Categories of the Commons: Theoretical Framework',\n",
    "           ha='center', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Add layer labels\n",
    "    ax.text(0.3, 8.25, 'Data Layer', fontsize=10, rotation=90, va='center')\n",
    "    ax.text(0.3, 4.75, 'Theory Layer', fontsize=10, rotation=90, va='center')\n",
    "    ax.text(0.3, 1.5, 'Output Layer', fontsize=10, rotation=90, va='center')\n",
    "    \n",
    "    # Add functor notation\n",
    "    ax.text(12.5, 4.75, 'F: OSS → Gov', fontsize=10, style='italic',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.text(12.5, 4.25, 'Functor mapping', fontsize=8, alpha=0.7)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig4 = create_framework_diagram()\n",
    "fig4.savefig(FIGURES_DIR / 'fig4_framework_diagram.png')\n",
    "fig4.savefig(FIGURES_DIR / 'fig4_framework_diagram.pdf')\n",
    "print(f\"Saved Figure 4 to {FIGURES_DIR}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1: Project Classification Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create publication-ready classification table.\"\"\"\n",
    "    table_df = df[['project', 'classification', 'confidence', 'entropy', \n",
    "                   'gini', 'top1_pct', 'contributors', 'stars']].copy()\n",
    "    \n",
    "    # Format columns\n",
    "    table_df['confidence'] = (table_df['confidence'] * 100).round(0).astype(int).astype(str) + '%'\n",
    "    table_df['entropy'] = table_df['entropy'].round(2)\n",
    "    table_df['gini'] = table_df['gini'].round(3)\n",
    "    table_df['top1_pct'] = table_df['top1_pct'].round(1).astype(str) + '%'\n",
    "    table_df['stars'] = table_df['stars'].apply(lambda x: f\"{x:,}\")\n",
    "    \n",
    "    # Rename columns for publication\n",
    "    table_df.columns = ['Project', 'Classification', 'Confidence', \n",
    "                       'H (bits)', 'Gini', 'Top 1%', 'N Contributors', 'Stars']\n",
    "    \n",
    "    return table_df\n",
    "\n",
    "if len(df) > 0:\n",
    "    table1 = create_classification_table(df)\n",
    "    \n",
    "    # Save as CSV and LaTeX\n",
    "    table1.to_csv(TABLES_DIR / 'table1_classification.csv', index=False)\n",
    "    table1.to_latex(TABLES_DIR / 'table1_classification.tex', index=False,\n",
    "                    caption='Project Classification Summary',\n",
    "                    label='tab:classification')\n",
    "    \n",
    "    print(f\"\\nTable 1: Project Classification Summary\\n\")\n",
    "    print(table1.to_string(index=False))\n",
    "    print(f\"\\nSaved to {TABLES_DIR}\")\n",
    "else:\n",
    "    print(\"No data for table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: Statistical Summary by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statistics_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create statistical summary table by category.\"\"\"\n",
    "    stats = df.groupby('category').agg({\n",
    "        'project': 'count',\n",
    "        'entropy': ['mean', 'std'],\n",
    "        'normalized_entropy': ['mean', 'std'],\n",
    "        'gini': ['mean', 'std'],\n",
    "        'top1_pct': ['mean', 'std'],\n",
    "        'contributors': ['mean', 'median'],\n",
    "        'stars': ['mean', 'median']\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n",
    "    stats = stats.reset_index()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "if len(df) > 0 and len(df['category'].unique()) > 1:\n",
    "    table2 = create_statistics_table(df)\n",
    "    \n",
    "    # Save as CSV and LaTeX\n",
    "    table2.to_csv(TABLES_DIR / 'table2_statistics.csv', index=False)\n",
    "    table2.to_latex(TABLES_DIR / 'table2_statistics.tex', index=False,\n",
    "                    caption='Statistical Summary by Governance Category',\n",
    "                    label='tab:statistics')\n",
    "    \n",
    "    print(f\"\\nTable 2: Statistical Summary by Category\\n\")\n",
    "    print(table2.to_string(index=False))\n",
    "    print(f\"\\nSaved to {TABLES_DIR}\")\n",
    "else:\n",
    "    print(\"Insufficient data for statistical summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary: Stadium Criteria Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stadium_criteria_figure(df: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"Visualize Stadium classification criteria.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    thresholds = {\n",
    "        'top1_pct': (40, 'Top Contributor > 40%'),\n",
    "        'gini': (0.8, 'Gini > 0.8'),\n",
    "        'normalized_entropy': (0.6, 'Normalized Entropy < 0.6')\n",
    "    }\n",
    "    \n",
    "    for idx, (metric, (threshold, title)) in enumerate(thresholds.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Color by whether threshold is met\n",
    "        if metric == 'normalized_entropy':\n",
    "            colors = ['#E74C3C' if v < threshold else '#3498DB' for v in df[metric]]\n",
    "        else:\n",
    "            colors = ['#E74C3C' if v > threshold else '#3498DB' for v in df[metric]]\n",
    "        \n",
    "        bars = ax.barh(range(len(df)), df[metric], color=colors, alpha=0.7)\n",
    "        ax.axvline(x=threshold, color='red', linestyle='--', linewidth=2, label='Threshold')\n",
    "        \n",
    "        # Labels\n",
    "        short_names = [p.split('/')[-1][:12] for p in df['project']]\n",
    "        ax.set_yticks(range(len(df)))\n",
    "        ax.set_yticklabels(short_names)\n",
    "        ax.set_title(title)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Legend\n",
    "    fig.suptitle('Stadium Classification Criteria', fontsize=14, y=1.02)\n",
    "    red_patch = mpatches.Patch(color='#E74C3C', label='Meets Stadium Criterion')\n",
    "    blue_patch = mpatches.Patch(color='#3498DB', label='Does Not Meet')\n",
    "    fig.legend(handles=[red_patch, blue_patch], loc='upper right', \n",
    "               bbox_to_anchor=(0.98, 0.98))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if len(df) > 0:\n",
    "    fig_supp = create_stadium_criteria_figure(df)\n",
    "    fig_supp.savefig(FIGURES_DIR / 'fig_supp_stadium_criteria.png')\n",
    "    fig_supp.savefig(FIGURES_DIR / 'fig_supp_stadium_criteria.pdf')\n",
    "    print(f\"Saved supplementary figure to {FIGURES_DIR}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate All Outputs Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PUBLICATION OUTPUTS GENERATED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nFigures:\")\n",
    "for f in sorted(FIGURES_DIR.glob('*')):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nTables:\")\n",
    "for f in sorted(TABLES_DIR.glob('*')):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready for LaTeX/paper integration\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Citation-Ready Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_stats(df: pd.DataFrame, projects: Dict) -> str:\n",
    "    \"\"\"Generate summary statistics for paper abstract/results.\"\"\"\n",
    "    if len(df) == 0:\n",
    "        return \"No data available for summary\"\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "SUMMARY STATISTICS FOR PUBLICATION\n",
    "{'=' * 50}\n",
    "\n",
    "Dataset:\n",
    "- Total projects analyzed: {len(df)}\n",
    "- Total contributors across projects: {df['contributors'].sum():,}\n",
    "- Combined GitHub stars: {df['stars'].sum():,}\n",
    "\n",
    "Classification Results:\n",
    "\"\"\"\n",
    "    \n",
    "    for cat in df['category'].unique():\n",
    "        count = len(df[df['category'] == cat])\n",
    "        pct = count / len(df) * 100\n",
    "        summary += f\"- {cat}: {count} projects ({pct:.1f}%)\\n\"\n",
    "    \n",
    "    summary += f\"\"\"\n",
    "Key Metrics (Mean ± SD):\n",
    "- Shannon Entropy: {df['entropy'].mean():.2f} ± {df['entropy'].std():.2f} bits\n",
    "- Gini Coefficient: {df['gini'].mean():.3f} ± {df['gini'].std():.3f}\n",
    "- Top Contributor %: {df['top1_pct'].mean():.1f}% ± {df['top1_pct'].std():.1f}%\n",
    "\n",
    "Stadium Projects Characteristics:\n",
    "\"\"\"\n",
    "    \n",
    "    stadium_df = df[df['category'] == 'Stadium']\n",
    "    if len(stadium_df) > 0:\n",
    "        summary += f\"- Average Gini: {stadium_df['gini'].mean():.3f}\\n\"\n",
    "        summary += f\"- Average Top Contributor: {stadium_df['top1_pct'].mean():.1f}%\\n\"\n",
    "        summary += f\"- Average Normalized Entropy: {stadium_df['normalized_entropy'].mean():.3f}\\n\"\n",
    "    else:\n",
    "        summary += \"- No Stadium projects classified yet\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "summary_text = generate_summary_stats(df, projects)\n",
    "print(summary_text)\n",
    "\n",
    "# Save summary\n",
    "with open(TABLES_DIR / 'summary_statistics.txt', 'w') as f:\n",
    "    f.write(summary_text)\n",
    "print(f\"\\nSaved summary to {TABLES_DIR / 'summary_statistics.txt'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
