{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Sheaf Cohomology Analysis\n",
    "\n",
    "Apply sheaf-theoretic framework to measure governance coherence in OSS projects.\n",
    "\n",
    "**Theoretical Foundation:** See `theory/sheaf-cohomology-framework.md`\n",
    "\n",
    "**Goals:**\n",
    "1. Construct project topology from contributor/module data\n",
    "2. Build governance sheaf from extracted rules/decisions/monitoring\n",
    "3. Compute Čech cohomology groups (H⁰, H¹, H²)\n",
    "4. Calculate cohomological health index χ_gov\n",
    "5. Test fork prediction hypothesis (H² spike precedes forks)\n",
    "\n",
    "**Key Hypotheses (from H7):**\n",
    "- H² spike precedes fork events by 6-12 months\n",
    "- H¹ correlates with organizational entropy\n",
    "- χ_gov predicts project sustainability\n",
    "- Quadrant-specific cohomology signatures exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport json\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dotenv import load_dotenv\n\n# Add src to path\nsys.path.insert(0, '../src')\nsys.path.insert(0, '../data')\n\nfrom analysis.entropy_calculation import EntropyCalculator\n\n# Load environment from .env file\nenv_path = Path(\"../.env\")\nif env_path.exists():\n    load_dotenv(env_path)\n    print(f\"✅ Loaded .env from {env_path.resolve()}\")\nelse:\n    load_dotenv()\n\n# Visualization settings\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('husl')\n\nprint(\"✅ Setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical Background\n",
    "\n",
    "### Sheaf Theory for OSS Governance\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "| Sheaf Concept | OSS Interpretation |\n",
    "|---------------|--------------------|\n",
    "| Base Space X | Project topology (contributors, modules, time periods) |\n",
    "| Open Sets U | Subprojects, teams, modules |\n",
    "| Stalks | Local governance data at a point |\n",
    "| Sections | Consistent governance rules across regions |\n",
    "| Gluing Axiom | Local decisions combine into coherent global policy |\n",
    "\n",
    "### Čech Cohomology Interpretation\n",
    "\n",
    "| Cohomology | Meaning |\n",
    "|------------|--------|\n",
    "| H⁰ | Global sections = universal governance rules |\n",
    "| H¹ | Governance conflicts = incompatible local policies |\n",
    "| H² | Structural obstructions = deep incompatibilities, fork precursors |\n",
    "\n",
    "### Health Metrics\n",
    "\n",
    "**Cohomological Health Index:**\n",
    "$$\\chi_{gov}(X) = \\dim H^0 - \\dim H^1 + \\dim H^2$$\n",
    "\n",
    "**Governance Health Ratio:**\n",
    "$$\\rho_{gov}(X) = \\frac{\\dim H^0}{\\dim H^0 + \\dim H^1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all collected project data\n",
    "data_dir = Path(\"../data/raw\")\n",
    "data_files = list(data_dir.glob(\"*_data.json\"))\n",
    "\n",
    "print(f\"Found {len(data_files)} collected projects:\\n\")\n",
    "\n",
    "projects = {}\n",
    "for f in sorted(data_files):\n",
    "    repo_name = f.stem.replace('_data', '').replace('_', '/')\n",
    "    with open(f) as fp:\n",
    "        projects[repo_name] = json.load(fp)\n",
    "    stars = projects[repo_name].get('repository', {}).get('stargazers_count', 0)\n",
    "    print(f\"  - {repo_name}: {stars:,} stars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Project Topology\n",
    "\n",
    "Construct the simplicial complex representing project structure:\n",
    "- **0-simplices (vertices):** Contributors\n",
    "- **1-simplices (edges):** Collaboration relationships\n",
    "- **2-simplices (triangles):** Team structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_collaboration_matrix(project_data):\n",
    "    \"\"\"\n",
    "    Build collaboration matrix from project data.\n",
    "    \n",
    "    Contributors are considered to collaborate if they:\n",
    "    - Reviewed each other's PRs\n",
    "    - Contributed to the same files\n",
    "    - Participated in the same issues\n",
    "    \"\"\"\n",
    "    contributors = project_data.get('contributors', [])\n",
    "    if not contributors:\n",
    "        return None, []\n",
    "    \n",
    "    # Get contributor names\n",
    "    names = [c['login'] for c in contributors[:50]]  # Limit to top 50\n",
    "    n = len(names)\n",
    "    \n",
    "    # Initialize collaboration matrix\n",
    "    collab = np.zeros((n, n))\n",
    "    \n",
    "    # Use contribution counts as proxy for collaboration strength\n",
    "    # More sophisticated: analyze PR reviews, co-commits, issue discussions\n",
    "    contributions = np.array([c['contributions'] for c in contributors[:50]])\n",
    "    \n",
    "    # Simple model: collaboration strength ~ geometric mean of contributions\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            collab[i,j] = np.sqrt(contributions[i] * contributions[j])\n",
    "            collab[j,i] = collab[i,j]\n",
    "    \n",
    "    # Normalize\n",
    "    if collab.max() > 0:\n",
    "        collab = collab / collab.max()\n",
    "    \n",
    "    return collab, names\n",
    "\n",
    "# Test on first project\n",
    "test_project = list(projects.keys())[0]\n",
    "collab_matrix, contributor_names = build_collaboration_matrix(projects[test_project])\n",
    "\n",
    "if collab_matrix is not None:\n",
    "    print(f\"Project: {test_project}\")\n",
    "    print(f\"Contributors: {len(contributor_names)}\")\n",
    "    print(f\"Collaboration matrix shape: {collab_matrix.shape}\")\n",
    "    print(f\"Non-zero collaborations: {np.count_nonzero(collab_matrix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize collaboration network\n",
    "if collab_matrix is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Show top 20 contributors\n",
    "    n_show = min(20, len(contributor_names))\n",
    "    \n",
    "    im = ax.imshow(collab_matrix[:n_show, :n_show], cmap='Blues')\n",
    "    ax.set_xticks(range(n_show))\n",
    "    ax.set_yticks(range(n_show))\n",
    "    ax.set_xticklabels(contributor_names[:n_show], rotation=45, ha='right')\n",
    "    ax.set_yticklabels(contributor_names[:n_show])\n",
    "    ax.set_title(f\"Collaboration Matrix: {test_project}\")\n",
    "    plt.colorbar(im, ax=ax, label='Collaboration Strength')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Governance Sheaf\n",
    "\n",
    "Extract governance data for each region of the project:\n",
    "- **Rules (R):** Coding standards, review requirements, CI checks\n",
    "- **Decisions (D):** Merge patterns, issue resolution, RFC processes\n",
    "- **Monitoring (M):** CI/CD, bots, review requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_governance_section(project_data):\n",
    "    \"\"\"\n",
    "    Extract governance data from project.\n",
    "    Returns a governance section (rules, decisions, monitoring).\n",
    "    \"\"\"\n",
    "    governance = {\n",
    "        'rules': set(),\n",
    "        'decisions': set(),\n",
    "        'monitoring': set()\n",
    "    }\n",
    "    \n",
    "    # Rules from governance files\n",
    "    gov_files = project_data.get('governance_files', {})\n",
    "    for file_type, content in gov_files.items():\n",
    "        if content:\n",
    "            governance['rules'].add(f'has_{file_type}')\n",
    "    \n",
    "    # Decision patterns from PR data\n",
    "    pr_stats = project_data.get('pull_requests', {}).get('statistics', {})\n",
    "    if pr_stats:\n",
    "        merge_rate = pr_stats.get('merged_count', 0) / max(pr_stats.get('total_prs', 1), 1)\n",
    "        governance['decisions'].add(f'merge_rate_{int(merge_rate*10)*10}')\n",
    "        \n",
    "        avg_time = pr_stats.get('avg_time_to_merge', 0)\n",
    "        if avg_time < 24:\n",
    "            governance['decisions'].add('fast_merge')\n",
    "        elif avg_time > 168:  # > 1 week\n",
    "            governance['decisions'].add('slow_merge')\n",
    "    \n",
    "    # Monitoring from maintainer data\n",
    "    maintainers = project_data.get('maintainers', {}).get('statistics', {})\n",
    "    active = maintainers.get('active_maintainers_6mo', 0)\n",
    "    if active <= 3:\n",
    "        governance['monitoring'].add('stadium_style')\n",
    "    elif active <= 10:\n",
    "        governance['monitoring'].add('club_style')\n",
    "    else:\n",
    "        governance['monitoring'].add('federation_style')\n",
    "    \n",
    "    return governance\n",
    "\n",
    "# Extract governance for all projects\n",
    "governance_data = {}\n",
    "for repo, data in projects.items():\n",
    "    governance_data[repo] = extract_governance_section(data)\n",
    "\n",
    "# Display sample\n",
    "print(\"Sample Governance Sections:\\n\")\n",
    "for repo in list(governance_data.keys())[:3]:\n",
    "    print(f\"{repo}:\")\n",
    "    for category, items in governance_data[repo].items():\n",
    "        print(f\"  {category}: {items}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Čech Cohomology (Simplified)\n",
    "\n",
    "For this initial implementation, we use a simplified cohomology calculation:\n",
    "\n",
    "- **H⁰ (Global Sections):** Count of governance rules that apply universally\n",
    "- **H¹ (Conflicts):** Measure of governance inconsistencies\n",
    "- **H² (Obstructions):** Higher-order structural issues\n",
    "\n",
    "A full implementation would use GUDHI or Dionysus for proper simplicial cohomology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simplified_cohomology(project_data, governance_section):\n",
    "    \"\"\"\n",
    "    Compute simplified cohomology metrics.\n",
    "    \n",
    "    This is a proxy calculation - full implementation would use\n",
    "    proper Čech complex construction and linear algebra.\n",
    "    \"\"\"\n",
    "    # H⁰: Global governance rules (count of formal governance indicators)\n",
    "    h0 = len(governance_section['rules'])\n",
    "    \n",
    "    # H¹: Governance conflicts (proxy: contributor concentration + PR conflict rate)\n",
    "    contributors = project_data.get('contributors', [])\n",
    "    if contributors:\n",
    "        total = sum(c['contributions'] for c in contributors)\n",
    "        top = contributors[0]['contributions'] if contributors else 0\n",
    "        concentration = top / max(total, 1)\n",
    "        \n",
    "        # High concentration with multiple contributors = potential conflict\n",
    "        if concentration > 0.5 and len(contributors) > 5:\n",
    "            h1 = 2  # Moderate conflict potential\n",
    "        elif concentration > 0.7:\n",
    "            h1 = 1  # Low conflict (BDFL model)\n",
    "        else:\n",
    "            h1 = len(contributors) // 20  # More contributors = more potential conflicts\n",
    "    else:\n",
    "        h1 = 0\n",
    "    \n",
    "    pr_stats = project_data.get('pull_requests', {}).get('statistics', {})\n",
    "    conflict_rate = pr_stats.get('conflict_rate', 0)\n",
    "    if conflict_rate > 0.1:\n",
    "        h1 += 1\n",
    "    \n",
    "    # H²: Structural obstructions (proxy: lack of governance docs + high contributor count)\n",
    "    gov_files = project_data.get('governance_files', {})\n",
    "    has_governance_docs = any(gov_files.values())\n",
    "    maintainers = project_data.get('maintainers', {}).get('statistics', {})\n",
    "    active = maintainers.get('active_maintainers_6mo', 0)\n",
    "    \n",
    "    h2 = 0\n",
    "    if not has_governance_docs and active > 5:\n",
    "        h2 = 1  # Missing governance with many contributors = structural issue\n",
    "    if active > 15 and len(governance_section['rules']) < 2:\n",
    "        h2 += 1  # Many people, few rules = potential for deep conflicts\n",
    "    \n",
    "    # Calculate health metrics\n",
    "    chi_gov = h0 - h1 + h2  # Euler characteristic-like\n",
    "    rho_gov = h0 / max(h0 + h1, 1)  # Health ratio\n",
    "    \n",
    "    return {\n",
    "        'H0': h0,\n",
    "        'H1': h1,\n",
    "        'H2': h2,\n",
    "        'chi_gov': chi_gov,\n",
    "        'rho_gov': rho_gov\n",
    "    }\n",
    "\n",
    "# Compute cohomology for all projects\n",
    "cohomology_results = {}\n",
    "for repo, data in projects.items():\n",
    "    gov = governance_data[repo]\n",
    "    cohomology_results[repo] = compute_simplified_cohomology(data, gov)\n",
    "\n",
    "# Display results\n",
    "print(\"Cohomology Results:\\n\")\n",
    "print(f\"{'Project':<40} {'H⁰':>4} {'H¹':>4} {'H²':>4} {'χ_gov':>6} {'ρ_gov':>6}\")\n",
    "print(\"─\" * 70)\n",
    "for repo, result in cohomology_results.items():\n",
    "    print(f\"{repo:<40} {result['H0']:>4} {result['H1']:>4} {result['H2']:>4} {result['chi_gov']:>6} {result['rho_gov']:>6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cohomology by Project Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify projects and analyze cohomology by type\n",
    "entropy_calc = EntropyCalculator()\n",
    "\n",
    "cohomology_df = []\n",
    "for repo, data in projects.items():\n",
    "    contributors = data.get('contributors', [])\n",
    "    classification = entropy_calc.classify_project(contributors)\n",
    "    coh = cohomology_results[repo]\n",
    "    \n",
    "    cohomology_df.append({\n",
    "        'repo': repo,\n",
    "        'classification': classification['classification'],\n",
    "        'H0': coh['H0'],\n",
    "        'H1': coh['H1'],\n",
    "        'H2': coh['H2'],\n",
    "        'chi_gov': coh['chi_gov'],\n",
    "        'rho_gov': coh['rho_gov'],\n",
    "        'entropy': classification['metrics'].get('normalized_entropy', 0),\n",
    "        'gini': classification['metrics'].get('gini_coefficient', 0)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(cohomology_df)\n",
    "\n",
    "# Summary by classification\n",
    "print(\"Cohomology by Project Type:\\n\")\n",
    "summary = df.groupby('classification').agg({\n",
    "    'H0': 'mean',\n",
    "    'H1': 'mean',\n",
    "    'H2': 'mean',\n",
    "    'chi_gov': 'mean',\n",
    "    'rho_gov': 'mean',\n",
    "    'repo': 'count'\n",
    "}).rename(columns={'repo': 'count'})\n",
    "\n",
    "print(summary.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cohomology metrics\n",
    "if len(df) > 1:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # H⁰ vs H¹\n",
    "    ax = axes[0]\n",
    "    for cls in df['classification'].unique():\n",
    "        subset = df[df['classification'] == cls]\n",
    "        ax.scatter(subset['H0'], subset['H1'], label=cls, alpha=0.7, s=100)\n",
    "    ax.set_xlabel('H⁰ (Global Sections)')\n",
    "    ax.set_ylabel('H¹ (Conflicts)')\n",
    "    ax.set_title('Governance Cohomology')\n",
    "    ax.legend()\n",
    "    \n",
    "    # χ_gov distribution\n",
    "    ax = axes[1]\n",
    "    df.boxplot(column='chi_gov', by='classification', ax=ax)\n",
    "    ax.set_title('Cohomological Health Index')\n",
    "    ax.set_xlabel('Classification')\n",
    "    ax.set_ylabel('χ_gov')\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    # ρ_gov distribution\n",
    "    ax = axes[2]\n",
    "    df.boxplot(column='rho_gov', by='classification', ax=ax)\n",
    "    ax.set_title('Governance Health Ratio')\n",
    "    ax.set_xlabel('Classification')\n",
    "    ax.set_ylabel('ρ_gov')\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/cohomology_by_type.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entropy-Cohomology Correlation\n",
    "\n",
    "Test hypothesis: H¹ correlates with organizational entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "if len(df) > 3:\n",
    "    # Correlation between H¹ and entropy\n",
    "    corr_h1_entropy, p_h1 = stats.pearsonr(df['H1'], df['entropy'])\n",
    "    print(f\"H¹ vs Entropy: r = {corr_h1_entropy:.3f}, p = {p_h1:.4f}\")\n",
    "    \n",
    "    # Correlation between χ_gov and Gini\n",
    "    corr_chi_gini, p_chi = stats.pearsonr(df['chi_gov'], df['gini'])\n",
    "    print(f\"χ_gov vs Gini: r = {corr_chi_gini:.3f}, p = {p_chi:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.scatter(df['entropy'], df['H1'], alpha=0.7)\n",
    "    ax.set_xlabel('Normalized Entropy')\n",
    "    ax.set_ylabel('H¹ (Conflicts)')\n",
    "    ax.set_title(f'Entropy vs Conflicts (r={corr_h1_entropy:.2f})')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.scatter(df['gini'], df['chi_gov'], alpha=0.7)\n",
    "    ax.set_xlabel('Gini Coefficient')\n",
    "    ax.set_ylabel('χ_gov (Health Index)')\n",
    "    ax.set_title(f'Inequality vs Health (r={corr_chi_gini:.2f})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Need more projects for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "### Immediate\n",
    "1. **Collect more projects** - Need 25-30 for statistical power\n",
    "2. **Implement proper Čech complex** using GUDHI library\n",
    "3. **Add temporal analysis** - Track cohomology over time\n",
    "\n",
    "### Fork Prediction Study\n",
    "1. Identify known fork events (Node.js/io.js, Bitcoin/Bitcoin Cash, etc.)\n",
    "2. Reconstruct historical project states\n",
    "3. Compute H² trajectory before fork\n",
    "4. Test prediction hypothesis\n",
    "\n",
    "### Full Implementation\n",
    "```python\n",
    "# TODO: Implement with GUDHI\n",
    "import gudhi\n",
    "\n",
    "def build_rips_complex(collab_matrix):\n",
    "    \"\"\"Build Rips complex from collaboration distances.\"\"\"\n",
    "    distance_matrix = 1.0 / (collab_matrix + 0.01)\n",
    "    rips = gudhi.RipsComplex(distance_matrix=distance_matrix, max_edge_length=2.0)\n",
    "    return rips.create_simplex_tree(max_dimension=3)\n",
    "\n",
    "def compute_persistence(simplex_tree):\n",
    "    \"\"\"Compute persistent homology.\"\"\"\n",
    "    simplex_tree.compute_persistence()\n",
    "    return simplex_tree.betti_numbers()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SHEAF COHOMOLOGY ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nProjects analyzed: {len(df)}\")\n",
    "print(f\"\\nMean cohomology values:\")\n",
    "print(f\"  H⁰ (Global Sections): {df['H0'].mean():.2f}\")\n",
    "print(f\"  H¹ (Conflicts): {df['H1'].mean():.2f}\")\n",
    "print(f\"  H² (Obstructions): {df['H2'].mean():.2f}\")\n",
    "print(f\"\\nHealth metrics:\")\n",
    "print(f\"  Mean χ_gov: {df['chi_gov'].mean():.2f}\")\n",
    "print(f\"  Mean ρ_gov: {df['rho_gov'].mean():.2f}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Categories)",
   "language": "python",
   "name": "categories-venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}